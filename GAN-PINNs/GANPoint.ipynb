{"cells":[{"cell_type":"markdown","metadata":{"id":"I_M5bLCUymUM"},"source":["# **Burger's equation**:\n","# $ u_t + u u_{xx} = v u_{xx} \\qquad x\\in[-1,1], \\quad t\\in [0,1], \\quad u ≡ u(x,t)$\n","\n","## Boundary conditions (Dirichlet):\n","* $ u(-1, t) = 0, \\qquad t\\in [0,1]$\n","* $ u(1, t) = 0, \\qquad t\\in [0,1]$\n","\n","## Initial condition:\n","* $ u(x, 0) = -\\sin(\\pi x), \\qquad x\\in[-1,1] $\n","\n","<!-- ## *ANALYTICAL SOLUTION*\n","## $ u(x, y, t) = e^{-13\\pi^2t}\\sin(3\\pi x)\\sin(2\\pi y)  $ -->\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VOI_YmDXZe-F"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3D4QbFPZhFL"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"z1DNgf78ZbRR"},"source":["# Helpers"]},{"cell_type":"markdown","metadata":{"id":"gNEEvUazVMr5"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgN6P2ZxVOJS"},"outputs":[],"source":["def generate_random_numbers(min_, max_, N, dtype):\n","    return min_ + (max_ - min_) * torch.rand(size=(N,), dtype=dtype)\n","\n","\n","class Data():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        self.x_min = x_min\n","        self.x_max = x_max\n","        self.t_min = t_min\n","        self.t_max = t_max\n","        self.Nx_domain = Nx_domain\n","        self.Nt_domain = Nt_domain\n","        self.Nx_init = Nx_init\n","        self.Nt_bound = Nt_bound\n","        self.N_test = N_test\n","        self.device = device\n","        self.dtype = dtype\n","\n","\n","    # *** Create in-domain points ***\n","    def sample_domain(self):\n","        # Random Grid\n","        x_domain = generate_random_numbers(self.x_min, self.x_max, self.Nx_domain, self.dtype)\n","        t_domain = generate_random_numbers(self.t_min, self.t_max, self.Nt_domain, self.dtype)\n","        domain_data = torch.stack(torch.meshgrid(x_domain, t_domain)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","        return domain_data\n","\n","    # *** Boundary Conditions ***\n","    def sample_boundary(self):\n","        # Random boundary points\n","        t_bound = generate_random_numbers(self.t_min, self.t_max, self.Nt_bound, self.dtype)\n","        x_left = - torch.ones(1, dtype=self.dtype)\n","        x_right = torch.ones(1, dtype=self.dtype)\n","\n","        bound_data_left = torch.stack(torch.meshgrid(x_left, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data_right = torch.stack(torch.meshgrid(x_right, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data = torch.cat([bound_data_left, bound_data_right]).requires_grad_(True).to(self.device)\n","\n","        u_bound = torch.zeros(len(bound_data), 1, dtype=self.dtype, device=self.device)\n","\n","        return bound_data, u_bound\n","\n","\n","    # *** Initial Condition ***\n","    def sample_initial(self):\n","        # Random initial points\n","        x_init = generate_random_numbers(self.x_min, self.x_max, self.Nx_init, self.dtype)\n","        t_init = torch.zeros(1, dtype=self.dtype)\n","        init_data = torch.stack(torch.meshgrid(x_init, t_init)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","\n","        u_init = - torch.sin(math.pi * x_init)\n","\n","        return init_data, u_init\n","\n","    # *** Test set ***\n","    def sample_test(self):\n","        x_test = self.x_min + (self.x_max - self.x_min) * torch.rand(self.N_test)\n","        t_test = self.t_min + (self.t_max - self.t_min) * torch.rand(self.N_test)\n","        return torch.stack([x_test, t_test], dim=1).requires_grad_(True).to(self.device)"]},{"cell_type":"markdown","metadata":{"id":"TZmOZNCYU4Oz"},"source":["## Networks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrYO4dPrrWP9"},"outputs":[],"source":["class MLPBase(nn.Module):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__()\n","        self.n_layers = len(layers) - 1\n","        self.layers = layers\n","        self.activation = activation\n","        self.weight_init = weight_init\n","        self.bias_init = bias_init\n","\n","        dense_layers = [\n","            self.dense_layer(in_features=self.layers[i], out_features=self.layers[i + 1])\n","            for i in range(self.n_layers - 1)]\n","        dense_layers.append(nn.Linear(in_features=self.layers[-2], out_features=self.layers[-1]))\n","\n","        self.mlp = nn.Sequential(*dense_layers).to(device)\n","\n","    def dense_layer(self, in_features, out_features):\n","        dense_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=out_features),\n","        )\n","\n","        if self.weight_init is not None:\n","            self.weight_init(dense_layer[0].weight)\n","\n","        if self.bias_init is not None:\n","            self.bias_init(dense_layer[0].bias)\n","\n","        dense_layer.add_module(\"activation\", self.activation)\n","        return dense_layer\n","\n","\n","class gMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        g_out = self.mlp(x)\n","        x_out = torch.tanh(g_out[:, 0].clone()).view(-1, 1)\n","        t_out = torch.sigmoid(g_out[:, 1].clone()).view(-1, 1)\n","        return torch.cat((x_out, t_out), dim=1)\n","\n","\n","class dMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S76p75oA73tM"},"outputs":[],"source":["class CNNDense(nn.Module):\n","    def __init__(self,\n","                 generator_num_batches,\n","                 num_filters,\n","                 kernel_size,\n","                 mlp_hidden_layers,\n","                 mlp_hidden_activation,\n","                 device='cpu'):\n","\n","        super().__init__()\n","        self.stride = 2\n","        self.padding = 0\n","        self.dilation = 1\n","\n","        base_layers = [\n","            nn.Conv1d(in_channels=4,\n","                      out_channels=num_filters,\n","                      kernel_size=kernel_size,\n","                      stride=self.stride),\n","            nn.BatchNorm1d(num_filters),\n","            nn.ReLU(),\n","            nn.Flatten()\n","        ]\n","\n","        conv1d_output_size = int(np.floor(1 + (generator_num_batches + 2*self.padding - self.dilation*(kernel_size - 1) - 1) / self.stride))\n","        mlp_in_features = conv1d_output_size * num_filters\n","\n","        mlp_layers = [mlp_in_features] + mlp_hidden_layers + [2]\n","\n","        self.cnn_layer = nn.Sequential(*base_layers).to(device)\n","        self.g_mlp = gMLP(layers=mlp_layers,\n","                          activation=mlp_hidden_activation,\n","                          device=device)\n","\n","\n","    def forward(self, x):\n","        cnn_output = self.cnn_layer(x)\n","        return self.g_mlp(cnn_output)"]},{"cell_type":"markdown","metadata":{"id":"CJoBS0b7Kb6Z"},"source":["## Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YwYgjRW3wzb"},"outputs":[],"source":["class Generator():\n","    def __init__(self,\n","                 generator_num_batches,\n","                 num_filters,\n","                 kernel_size,\n","                 mlp_hidden_layers,\n","                 mlp_hidden_activation,\n","                 device):\n","\n","        # Define the model\n","        self.model = CNNDense(generator_num_batches,\n","                              num_filters,\n","                              kernel_size,\n","                              mlp_hidden_layers,\n","                              mlp_hidden_activation)\n","\n","        # Set the optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters())\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def calculate_loss(self, fake_data, discriminator):\n","        _, pde_res = discriminator.calculate_pde_residual(fake_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return - discriminator.criterion(pde_res, pde_target)\n","\n","\n","    def train(self, fake_data, discriminator):\n","        # \"Zero\" the gradients\n","        self.optimizer.zero_grad()\n","\n","        # Calculate loss\n","        loss = self.calculate_loss(fake_data, discriminator)\n","\n","        # Backpropagate the loss\n","        loss.backward()\n","\n","        # Implement one step of gradient descent\n","        self.optimizer.step()\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"difNKQa1Kewd"},"source":["## Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjJ_f5zo63WW"},"outputs":[],"source":["class Discriminator():\n","    def __init__(self,\n","                 layers,\n","                 activation,\n","                 device):\n","\n","        self.v = 0.01 / math.pi\n","\n","        # Define the model\n","        self.model = dMLP(layers=layers,\n","                          activation=activation,\n","                          weight_init=lambda m: nn.init.xavier_normal_(m.data, nn.init.calculate_gain('tanh')),\n","                          bias_init=lambda m: nn.init.zeros_(m.data),\n","                          device=device)\n","\n","        # Set the optimizers\n","        adam = torch.optim.Adam(self.model.parameters())\n","        lbfgs = torch.optim.LBFGS(self.model.parameters(),\n","                                  lr=1,\n","                                  max_iter=2000,\n","                                  max_eval=None,\n","                                  tolerance_grad=1e-07,\n","                                  tolerance_change=1e-09,\n","                                  history_size=100,\n","                                  line_search_fn='strong_wolfe')\n","\n","        self.optimizers = {\"adam\": adam, \"lbfgs\": lbfgs}\n","\n","        # Set the Loss function\n","        self.criterion = nn.MSELoss()\n","\n","        # Set the MAE criterion for test data only\n","        self.l1_loss = nn.L1Loss()\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def grad(self, output, input):\n","        return torch.autograd.grad(\n","                    output, input,\n","                    grad_outputs=torch.ones_like(output),\n","                    retain_graph=True,\n","                    create_graph=True\n","                )[0]\n","\n","\n","    def calculate_pde_residual(self, x):\n","        # Forward pass\n","        u = self.forward(x)\n","\n","        # Calculate 1st and 2nd derivatives\n","        du_dX = self.grad(u, x)\n","        du_dXX = self.grad(du_dX, x)\n","\n","        # Retrieve the partial gradients\n","        du_dt = du_dX[:, 1].flatten()\n","        du_dx = du_dX[:, 0].flatten()\n","        du_dxx = du_dXX[:, 0].flatten()\n","\n","        return u, du_dt + u.flatten() * du_dx - self.v * du_dxx\n","\n","\n","    def calculate_pde_loss(self, data):\n","        # Calculate the domain loss\n","        _, pde_res = self.calculate_pde_residual(data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.criterion(pde_res, pde_target)\n","\n","\n","    def calculate_real_loss(self, real_data):\n","        # Calculate boundary loss\n","        loss_b = self.criterion(\n","            self.forward(real_data[\"bound_data\"]).flatten(),\n","            real_data[\"u_bound\"].flatten()\n","        )\n","\n","        # Calculate initial loss\n","        loss_i = self.criterion(\n","            self.forward(real_data[\"init_data\"]).flatten(),\n","            real_data[\"u_init\"].flatten()\n","        )\n","\n","        # Calculate the domain loss\n","        loss_pde = self.calculate_pde_loss(real_data[\"domain_data\"])\n","\n","        # Calculate total discriminator loss\n","        return loss_b + loss_i + loss_pde\n","\n","\n","    def calculate_fake_loss(self, fake_data):\n","        return self.calculate_pde_loss(fake_data)\n","\n","\n","    def calculate_test_loss(self, test_data):\n","        _, pde_res = self.calculate_pde_residual(test_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.l1_loss(pde_res, pde_target)\n","\n","\n","    def train_on_real(self, real_data):\n","        loss_real = self.calculate_real_loss(real_data)\n","        loss_real.backward()\n","        return loss_real\n","\n","\n","    def train_on_fake(self, fake_data):\n","        loss_fake = self.calculate_fake_loss(fake_data.detach().requires_grad_(True))\n","        loss_fake.backward()\n","        return loss_fake\n","\n","\n","    def closure(self):\n","        self.lbfgs_optimizer.zero_grad()\n","        loss_real = self.train_on_real(self.real_data)\n","        loss_fake = self.train_on_fake(self.fake_data)\n","        return loss_real + loss_fake"]},{"cell_type":"markdown","metadata":{"id":"hNERHKrzFCeB"},"source":["## GAN-POINT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNUssAyw5MMh"},"outputs":[],"source":["class GANPoint():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound, N_test,\n","                 generator_num_batches, generator_batch_size,\n","                 g_layers, g_activation,\n","                 g_num_filters,\n","                 g_kernel_size,\n","                 d_layers, d_activation,\n","                 checkpoint_path,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        # Constants\n","        self.checkpoint_path = checkpoint_path\n","        self.device = device\n","        self.dtype = dtype\n","        self.generator_num_batches = generator_num_batches\n","        self.generator_batch_size = generator_batch_size\n","        self.N_noise = generator_num_batches * generator_batch_size\n","        self.N_test = N_test\n","\n","        # Create real data\n","        self.real_data_init = Data(x_min, x_max,\n","                                   t_min, t_max,\n","                                   Nx_domain, Nt_domain,\n","                                   Nx_init, Nt_bound,\n","                                   N_test,\n","                                   device,\n","                                   dtype)\n","\n","        # Create test data\n","        self.test_data = self.real_data_init.sample_test()\n","\n","        # Create Generator\n","        self.generator = self.build_generator(generator_num_batches,\n","                                              g_num_filters,\n","                                              g_kernel_size,\n","                                              g_layers,\n","                                              g_activation,\n","                                              device)\n","\n","        # Create Discriminator\n","        self.discriminator = Discriminator(d_layers, d_activation, device)\n","\n","\n","    def build_generator(self,\n","                        generator_num_batches,\n","                        g_num_filters,\n","                        g_kernel_size,\n","                        g_layers,\n","                        g_activation,\n","                        device):\n","\n","        def init_weights(layer):\n","            if isinstance(layer, nn.Conv1d) or isinstance(layer, nn.Linear):\n","                nn.init.xavier_normal_(layer.weight)\n","\n","                if layer.bias is not None:\n","                    nn.init.constant_(layer.bias, 0)\n","\n","        generator = Generator(generator_num_batches,\n","                              g_num_filters,\n","                              g_kernel_size,\n","                              g_layers,\n","                              g_activation,\n","                              device)\n","\n","        generator.model.apply(init_weights)\n","        return generator\n","\n","\n","    def generate_data(self):\n","        # Create real data\n","        real_data = {}\n","        real_data[\"domain_data\"] = self.real_data_init.sample_domain()\n","        real_data[\"bound_data\"], real_data[\"u_bound\"] = self.real_data_init.sample_boundary()\n","        real_data[\"init_data\"], real_data[\"u_init\"] = self.real_data_init.sample_initial()\n","\n","        # Create noise (Generator's input)\n","        random_tensor = torch.rand(self.N_noise, 2)  # 2 refers to (x, t)\n","        x_noise = 2 * random_tensor[:, 0] - 1\n","        t_noise = random_tensor[:, 1]\n","        noise = torch.cat((x_noise.view(-1, 1), t_noise.view(-1, 1)), dim=1)\n","\n","        return real_data, noise\n","\n","\n","    def train_with_adam(self, N_adam, real_data, fake_data):\n","        optimizer = self.discriminator.optimizers['adam']\n","\n","        for epoch in range(1, N_adam + 1):\n","            optimizer.zero_grad()\n","            loss_real = self.discriminator.train_on_real(real_data)\n","            loss_fake = self.discriminator.train_on_fake(fake_data)\n","            loss_D = loss_real + loss_fake\n","            optimizer.step()\n","\n","\n","    def train_with_lbfgs(self, N_lbfgs, real_data, fake_data):\n","        self.discriminator.lbfgs_optimizer = self.discriminator.optimizers[\"lbfgs\"]\n","        self.discriminator.real_data = real_data\n","        self.discriminator.fake_data = fake_data\n","\n","        for epoch in range(1, N_lbfgs + 1):\n","            loss_D = self.discriminator.lbfgs_optimizer.step(self.discriminator.closure)\n","\n","        return loss_D\n","\n","\n","    def checkpoint(self):\n","        torch.save({\n","            \"model\": self.discriminator.model.state_dict()\n","        }, self.checkpoint_path)\n","\n","\n","    def format_loss(self, loss):\n","        if loss == 0:\n","            return \"0.0e+00\"\n","\n","        # Calculate the exponent part\n","        exponent = int(math.log10(abs(loss)))\n","\n","        # Determine the format based on the value of the loss\n","        if abs(loss) < 1:\n","            formatted_loss = f\"{loss:.2e}\"\n","        else:\n","            # Adjust the sign of the formatted loss\n","            sign = \"-\" if loss < 0 else \"\"\n","\n","            # Calculate the number of decimal places\n","            decimal_places = 2 - exponent\n","\n","            # Ensure at least two decimal places\n","            decimal_places = max(decimal_places, 2)\n","\n","            # Format the loss with the correct sign\n","            formatted_loss = f\"{sign}{abs(loss):.{decimal_places}e}\"\n","\n","        return formatted_loss\n","\n","\n","    def keep_checkpoints_and_print_losses(self, iter, patience, print_every,\n","                                          loss_D, loss_G, loss_test):\n","\n","        loss_D_str = self.format_loss(loss_D)\n","        loss_G_str = self.format_loss(loss_G)\n","        loss_test_str = self.format_loss(loss_test)\n","\n","        if iter == 1:\n","            self.best_val_loss = loss_test\n","            self.best_epoch = -1\n","            self.checkpoint()\n","            self.flag = 1\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","        else:\n","            if loss_test < self.best_val_loss:\n","                self.best_val_loss = loss_test\n","                self.best_epoch = iter\n","                self.checkpoint()\n","                self.flag = 1\n","                if iter % print_every == 0:\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","            elif iter - self.best_epoch > patience:\n","                if iter % print_every == 0:\n","                    self.early_stopping_applied = 1\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str}\")\n","                return\n","\n","        if (self.flag == 0) and (iter % print_every == 0):\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str}\")\n","\n","\n","    def train(self, iters, patience, print_every, N_adam, N_lbfgs):\n","\n","        print(f\"GAN-PINN: {iters} iterations\")\n","        print(f\"a. PINN: {N_adam} epochs --> Adam\")\n","        print(f\"b. PINN: {N_lbfgs} epochs --> L-BFGS\")\n","        print(f\"c. Generator: 1 epoch --> Adam\\n\")\n","\n","        for iter in tqdm(range(1, iters + 1)):\n","            self.flag = 0\n","            self.early_stopping_applied = 0\n","\n","            real_data, noise = self.generate_data()\n","\n","            u_noise, pde_res_noise = self.discriminator.calculate_pde_residual(noise.requires_grad_(True))\n","\n","            generator_input = torch.cat((noise, u_noise.detach(), pde_res_noise.detach().view(-1, 1)), dim=1)\n","            generator_input = generator_input.view(self.generator_batch_size, 4, self.generator_num_batches)\n","\n","            fake_data = self.generator.model(generator_input)\n","\n","            self.train_with_adam(N_adam, real_data, fake_data)\n","            loss_D = self.train_with_lbfgs(N_lbfgs, real_data, fake_data)\n","            loss_G = self.generator.train(fake_data, self.discriminator)\n","\n","            loss_test = self.discriminator.calculate_test_loss(self.test_data)\n","\n","            self.keep_checkpoints_and_print_losses(iter, patience, print_every,\n","                                                   loss_D, loss_G, loss_test)\n","\n","            if self.early_stopping_applied:\n","                print(f\"\\nEarly stopping applied at epoch {iter}.\")\n","                break"]},{"cell_type":"markdown","metadata":{"id":"9766h9FaaM_k"},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":761,"referenced_widgets":["f9d4ec864f9b47dcb99ed1b8ab1ef862","6c0e3685e9c349debbfb70f63ca94536","f9d650ccd3ed424790ef07de7c119d33","9c93d9d9c8104d16b98444792658b1da","da6be560768f4150a2b185ca8f886524","ea12f708217e4ca5b64edd866a7ea916","c017169310fc47f38ddfd4bc9d8b031d","efafff3350524bffbb1681009bf9b551","2a30d3abec514cebaddb9eeeb743f7ba","ef381a582b86409e862f9064290b2dc9","c25b0524c3ff4cf58fc7216b88434dc9"]},"executionInfo":{"elapsed":1101688,"status":"ok","timestamp":1710613822668,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"},"user_tz":-120},"id":"Mxs5oZzT-PIf","outputId":"997757ae-a6ef-4b4a-b734-56326f863396"},"outputs":[{"name":"stdout","output_type":"stream","text":["GAN-PINN: 100 iterations\n","a. PINN: 100 epochs --> Adam\n","b. PINN: 1 epochs --> L-BFGS\n","c. Generator: 1 epoch --> Adam\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9d4ec864f9b47dcb99ed1b8ab1ef862","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Iteration: 1 | loss_D: 2.58e-01 | loss_G: -1.68e-04 | test_mae: 4.17e-02 - *Checkpoint*\n","Iteration: 2 | loss_D: 1.35e-02 | loss_G: -1.27e-05 | test_mae: 3.56e-02 - *Checkpoint*\n","Iteration: 3 | loss_D: 1.11e-02 | loss_G: -6.12e-06 | test_mae: 2.63e-02 - *Checkpoint*\n","Iteration: 4 | loss_D: 1.69e-03 | loss_G: -1.44e-06 | test_mae: 3.67e-02\n","Iteration: 5 | loss_D: 2.84e-03 | loss_G: -5.08e-07 | test_mae: 1.09e-02 - *Checkpoint*\n","Iteration: 6 | loss_D: 6.97e-04 | loss_G: -5.58e-07 | test_mae: 1.31e-02\n","Iteration: 7 | loss_D: 7.11e-04 | loss_G: -4.78e-07 | test_mae: 1.58e-02\n","Iteration: 8 | loss_D: 1.72e-03 | loss_G: -5.57e-07 | test_mae: 1.37e-02\n","Iteration: 9 | loss_D: 1.48e-03 | loss_G: -3.32e-07 | test_mae: 1.05e-02 - *Checkpoint*\n","Iteration: 10 | loss_D: 3.54e-04 | loss_G: -2.58e-07 | test_mae: 1.66e-02\n","Iteration: 11 | loss_D: 6.18e-04 | loss_G: -1.56e-06 | test_mae: 1.76e-02\n","Iteration: 12 | loss_D: 2.62e-04 | loss_G: -2.20e-07 | test_mae: 1.82e-02\n","Iteration: 13 | loss_D: 1.69e-03 | loss_G: -1.90e-07 | test_mae: 6.13e-03 - *Checkpoint*\n","Iteration: 14 | loss_D: 1.90e-04 | loss_G: -3.55e-07 | test_mae: 7.11e-03\n","Iteration: 15 | loss_D: 8.75e-05 | loss_G: -1.55e-07 | test_mae: 1.23e-02\n","Iteration: 16 | loss_D: 5.87e-04 | loss_G: -6.33e-07 | test_mae: 1.28e-02\n","Iteration: 17 | loss_D: 4.95e-03 | loss_G: -1.47e-07 | test_mae: 6.70e-03\n","Iteration: 18 | loss_D: 1.98e-04 | loss_G: -6.04e-08 | test_mae: 8.26e-03\n","Iteration: 19 | loss_D: 5.32e-04 | loss_G: -8.02e-08 | test_mae: 7.87e-03\n","Iteration: 20 | loss_D: 3.63e-04 | loss_G: -3.76e-07 | test_mae: 7.31e-03\n","Iteration: 21 | loss_D: 1.04e-04 | loss_G: -1.82e-07 | test_mae: 8.17e-03\n","Iteration: 22 | loss_D: 8.43e-04 | loss_G: -5.85e-07 | test_mae: 9.27e-03\n","Iteration: 23 | loss_D: 2.76e-04 | loss_G: -1.15e-07 | test_mae: 5.91e-03 - *Checkpoint*\n","Iteration: 24 | loss_D: 7.61e-05 | loss_G: -9.43e-08 | test_mae: 1.92e-02\n","Iteration: 25 | loss_D: 1.15e-03 | loss_G: -1.36e-07 | test_mae: 7.32e-03\n","Iteration: 26 | loss_D: 2.38e-04 | loss_G: -1.02e-07 | test_mae: 8.47e-03\n","Iteration: 27 | loss_D: 4.29e-05 | loss_G: -1.33e-07 | test_mae: 7.10e-03\n","Iteration: 28 | loss_D: 1.22e-04 | loss_G: -1.19e-07 | test_mae: 8.11e-03\n","Iteration: 29 | loss_D: 3.64e-04 | loss_G: -9.42e-08 | test_mae: 9.27e-03\n","Iteration: 30 | loss_D: 5.97e-04 | loss_G: -6.29e-07 | test_mae: 1.04e-02\n","Iteration: 31 | loss_D: 9.20e-05 | loss_G: -8.14e-08 | test_mae: 9.32e-03\n","Iteration: 32 | loss_D: 3.27e-04 | loss_G: -3.84e-07 | test_mae: 1.02e-02\n","Iteration: 33 | loss_D: 2.64e-04 | loss_G: -1.43e-07 | test_mae: 1.19e-02\n","Iteration: 34 | loss_D: 2.06e-04 | loss_G: -7.69e-07 | test_mae: 1.33e-02\n","\n","Early stopping applied at epoch 34.\n"]}],"source":["# Data\n","x_min, x_max = -1, 1\n","t_min, t_max = 0, 1\n","Nx_domain = 200\n","Nt_domain = 100\n","Nx_init = 100\n","Nt_bound = 100\n","N_test = 100_000\n","generator_num_batches = 512\n","generator_batch_size = 64\n","\n","# Generator\n","g_num_filters = 64\n","g_kernel_size = 3\n","Ng_layers = 3\n","Ng_neurons = 64\n","g_hidden_layers = Ng_layers * [Ng_neurons]\n","g_hidden_activation = nn.ReLU()\n","\n","# Discriminator\n","Nd_layers = 3\n","Nd_neurons = 20\n","d_layers = [2] + Nd_layers * [Nd_neurons] + [1]\n","d_hidden_activation = nn.Tanh()\n","\n","# Other\n","checkpoint_path = \"discriminator.pth\"\n","dtype = torch.float32\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# GAN-PINN initialization\n","gan_pinn = GANPoint(\n","    x_min, x_max,\n","    t_min, t_max,\n","    Nx_domain, Nt_domain,\n","    Nx_init, Nt_bound, N_test,\n","    generator_num_batches, generator_batch_size,\n","    g_hidden_layers, g_hidden_activation,\n","    g_num_filters,\n","    g_kernel_size,\n","    d_layers, d_hidden_activation,\n","    checkpoint_path\n",")\n","\n","# Training\n","iterations = 100\n","patience = 10\n","print_every = 1\n","num_epochs_adam = 100\n","num_epochs_lbfgs = 1\n","\n","gan_pinn.train(iterations, patience, print_every, num_epochs_adam, num_epochs_lbfgs)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPfaYxw/xM1tyyN4tl+xVdl","gpuType":"V100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2a30d3abec514cebaddb9eeeb743f7ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c0e3685e9c349debbfb70f63ca94536":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea12f708217e4ca5b64edd866a7ea916","placeholder":"​","style":"IPY_MODEL_c017169310fc47f38ddfd4bc9d8b031d","value":" 33%"}},"9c93d9d9c8104d16b98444792658b1da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef381a582b86409e862f9064290b2dc9","placeholder":"​","style":"IPY_MODEL_c25b0524c3ff4cf58fc7216b88434dc9","value":" 33/100 [20:44&lt;23:41, 21.22s/it]"}},"c017169310fc47f38ddfd4bc9d8b031d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c25b0524c3ff4cf58fc7216b88434dc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da6be560768f4150a2b185ca8f886524":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea12f708217e4ca5b64edd866a7ea916":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef381a582b86409e862f9064290b2dc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efafff3350524bffbb1681009bf9b551":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d4ec864f9b47dcb99ed1b8ab1ef862":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c0e3685e9c349debbfb70f63ca94536","IPY_MODEL_f9d650ccd3ed424790ef07de7c119d33","IPY_MODEL_9c93d9d9c8104d16b98444792658b1da"],"layout":"IPY_MODEL_da6be560768f4150a2b185ca8f886524"}},"f9d650ccd3ed424790ef07de7c119d33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_efafff3350524bffbb1681009bf9b551","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a30d3abec514cebaddb9eeeb743f7ba","value":33}}}}},"nbformat":4,"nbformat_minor":0}
