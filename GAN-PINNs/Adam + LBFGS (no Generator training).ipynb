{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"T4","mount_file_id":"1NpncNBi7anGacutGAkwFdHjcl4X_UNLq","authorship_tag":"ABX9TyNPNZK0DysBP9UBS+t6nONQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"12cbdd3e0440421fade9cccc1723450c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b21b393007d45e288ef0411f57a10a3","IPY_MODEL_ad65f4007dab4b82b8c23a79d502da5c","IPY_MODEL_d29382b1e75c4887b3880f2fb7dce2ef"],"layout":"IPY_MODEL_27f747e6ded9405280801bf9746225c4"}},"2b21b393007d45e288ef0411f57a10a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea7afd4ba0164eb1bfbb290bfdb9a2b8","placeholder":"​","style":"IPY_MODEL_77497726c1804c41a69de1ca47d914f9","value":" 57%"}},"ad65f4007dab4b82b8c23a79d502da5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_69de0318c2e846138d77395a2f154dcf","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ce3ae0f199f45dba22d2984ef19bf23","value":17}},"d29382b1e75c4887b3880f2fb7dce2ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebfce7513bee4d768202e440f9a97214","placeholder":"​","style":"IPY_MODEL_f7188b8e89db419b985d79115c0dcf15","value":" 17/30 [04:58&lt;03:36, 16.62s/it]"}},"27f747e6ded9405280801bf9746225c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea7afd4ba0164eb1bfbb290bfdb9a2b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77497726c1804c41a69de1ca47d914f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69de0318c2e846138d77395a2f154dcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ce3ae0f199f45dba22d2984ef19bf23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebfce7513bee4d768202e440f9a97214":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7188b8e89db419b985d79115c0dcf15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"I_M5bLCUymUM"},"source":["# **Burger's equation**:\n","# $ u_t + u u_{xx} = v u_{xx} \\qquad x\\in[-1,1], \\quad t\\in [0,1], \\quad u ≡ u(x,t)$\n","\n","## Boundary conditions (Dirichlet):\n","* $ u(-1, t) = 0, \\qquad t\\in [0,1]$\n","* $ u(1, t) = 0, \\qquad t\\in [0,1]$\n","\n","## Initial condition:\n","* $ u(x, 0) = -\\sin(\\pi x), \\qquad x\\in[-1,1] $\n","\n","<!-- ## *ANALYTICAL SOLUTION*\n","## $ u(x, y, t) = e^{-13\\pi^2t}\\sin(3\\pi x)\\sin(2\\pi y)  $ -->\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VOI_YmDXZe-F"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"X3D4QbFPZhFL","executionInfo":{"status":"ok","timestamp":1711133981416,"user_tz":-120,"elapsed":5662,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"z1DNgf78ZbRR"},"source":["# Helpers"]},{"cell_type":"markdown","metadata":{"id":"gNEEvUazVMr5"},"source":["## Data"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TgN6P2ZxVOJS","executionInfo":{"status":"ok","timestamp":1711133981417,"user_tz":-120,"elapsed":16,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"outputs":[],"source":["def generate_random_numbers(min_, max_, N, dtype):\n","    return min_ + (max_ - min_) * torch.rand(size=(N,), dtype=dtype)\n","\n","\n","class Data():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        self.x_min = x_min\n","        self.x_max = x_max\n","        self.t_min = t_min\n","        self.t_max = t_max\n","        self.Nx_domain = Nx_domain\n","        self.Nt_domain = Nt_domain\n","        self.Nx_init = Nx_init\n","        self.Nt_bound = Nt_bound\n","        self.N_test = N_test\n","        self.device = device\n","        self.dtype = dtype\n","\n","\n","    # *** Create in-domain points ***\n","    def sample_domain(self):\n","        # Random Grid\n","        x_domain = generate_random_numbers(self.x_min, self.x_max, self.Nx_domain, self.dtype)\n","        t_domain = generate_random_numbers(self.t_min, self.t_max, self.Nt_domain, self.dtype)\n","        domain_data = torch.stack((x_domain, t_domain), dim=1)\n","        # domain_data = torch.stack(torch.meshgrid(x_domain, t_domain)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","        return torch.tensor(domain_data, dtype=self.dtype, device=self.device, requires_grad=True)\n","\n","    # *** Boundary Conditions ***\n","    def sample_boundary(self):\n","        # Random boundary points\n","        t_bound = generate_random_numbers(self.t_min, self.t_max, self.Nt_bound, self.dtype)\n","        x_left = - torch.ones(1, dtype=self.dtype)\n","        x_right = torch.ones(1, dtype=self.dtype)\n","\n","        bound_data_left = torch.stack(torch.meshgrid(x_left, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data_right = torch.stack(torch.meshgrid(x_right, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data = torch.cat([bound_data_left, bound_data_right]).requires_grad_(True).to(self.device)\n","\n","        u_bound = torch.zeros(len(bound_data), 1, dtype=self.dtype, device=self.device)\n","\n","        return bound_data, u_bound\n","\n","\n","    # *** Initial Condition ***\n","    def sample_initial(self):\n","        # Random initial points\n","        x_init = generate_random_numbers(self.x_min, self.x_max, self.Nx_init, self.dtype)\n","        t_init = torch.zeros(1, dtype=self.dtype)\n","        init_data = torch.stack(torch.meshgrid(x_init, t_init)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","\n","        u_init = - torch.sin(math.pi * x_init).to(self.device)\n","\n","        return init_data, u_init\n","\n","    # *** Test set ***\n","    def sample_test(self):\n","        test_data = pd.read_csv('/content/drive/MyDrive/test_data.csv').dropna().to_numpy()\n","        return torch.tensor(test_data, dtype=self.dtype, device=self.device, requires_grad=True)\n","        # x_test = self.x_min + (self.x_max - self.x_min) * torch.rand(self.N_test)\n","        # t_test = self.t_min + (self.t_max - self.t_min) * torch.rand(self.N_test)\n","        # return torch.stack([x_test, t_test], dim=1).requires_grad_(True).to(self.device)"]},{"cell_type":"markdown","metadata":{"id":"TZmOZNCYU4Oz"},"source":["## Network"]},{"cell_type":"code","source":["class MLPBase(nn.Module):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__()\n","        self.n_layers = len(layers) - 1\n","        self.layers = layers\n","        self.activation = activation\n","        self.weight_init = weight_init\n","        self.bias_init = bias_init\n","\n","        dense_layers = [\n","            self.dense_layer(in_features=self.layers[i], out_features=self.layers[i + 1])\n","            for i in range(self.n_layers - 1)]\n","        dense_layers.append(nn.Linear(in_features=self.layers[-2], out_features=self.layers[-1]))\n","\n","        self.mlp = nn.Sequential(*dense_layers).to(device)\n","\n","    def dense_layer(self, in_features, out_features):\n","        dense_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=out_features),\n","        )\n","\n","        if self.weight_init is not None:\n","            self.weight_init(dense_layer[0].weight)\n","\n","        if self.bias_init is not None:\n","            self.bias_init(dense_layer[0].bias)\n","\n","        dense_layer.add_module(\"activation\", self.activation)\n","        return dense_layer\n","\n","\n","class dMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        return self.mlp(x)"],"metadata":{"id":"BrYO4dPrrWP9","executionInfo":{"status":"ok","timestamp":1711133981417,"user_tz":-120,"elapsed":14,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## PINN"],"metadata":{"id":"difNKQa1Kewd"}},{"cell_type":"code","source":["class PINN():\n","    def __init__(self,\n","                 layers,\n","                 activation,\n","                 device):\n","\n","        self.v = 0.01 / math.pi\n","\n","        # Define the model\n","        self.model = dMLP(layers=layers,\n","                          activation=activation,\n","                          weight_init=lambda m: nn.init.xavier_normal_(m.data, nn.init.calculate_gain('tanh')),\n","                          bias_init=lambda m: nn.init.zeros_(m.data),\n","                          device=device)\n","\n","        # Set the optimizers\n","        adam = torch.optim.Adam(self.model.parameters())\n","        lbfgs = torch.optim.LBFGS(self.model.parameters(),\n","                                  lr=1,\n","                                  max_iter=1_000,\n","                                  max_eval=None,\n","                                  tolerance_grad=1e-07,\n","                                  tolerance_change=1e-09,\n","                                  history_size=100,\n","                                  line_search_fn='strong_wolfe')\n","\n","        self.optimizers = {\"adam\": adam, \"lbfgs\": lbfgs}\n","\n","        # Set the Loss function\n","        self.criterion = nn.MSELoss()\n","\n","        # Set the MAE criterion for test data only\n","        self.l1_loss = nn.L1Loss()\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def grad(self, output, input):\n","        return torch.autograd.grad(\n","                    output, input,\n","                    grad_outputs=torch.ones_like(output),\n","                    retain_graph=True,\n","                    create_graph=True\n","                )[0]\n","\n","\n","    def calculate_pde_residual(self, x):\n","        # Forward pass\n","        u = self.forward(x)\n","\n","        # Calculate 1st and 2nd derivatives\n","        du_dX = self.grad(u, x)\n","        du_dXX = self.grad(du_dX, x)\n","\n","        # Retrieve the partial gradients\n","        du_dt = du_dX[:, 1].flatten()\n","        du_dx = du_dX[:, 0].flatten()\n","        du_dxx = du_dXX[:, 0].flatten()\n","\n","        return du_dt + u.flatten() * du_dx - self.v * du_dxx\n","\n","\n","    def calculate_pde_loss(self, data):\n","        # Calculate the domain loss\n","        pde_res = self.calculate_pde_residual(data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.criterion(pde_res, pde_target)\n","\n","\n","    def calculate_real_loss(self, real_data):\n","        # Calculate boundary loss\n","        loss_b = self.criterion(\n","            self.forward(real_data[\"bound_data\"]).flatten(),\n","            real_data[\"u_bound\"].flatten()\n","        )\n","\n","        # Calculate initial loss\n","        loss_i = self.criterion(\n","            self.forward(real_data[\"init_data\"]).flatten(),\n","            real_data[\"u_init\"].flatten()\n","        )\n","\n","        # Calculate the domain loss\n","        loss_pde = self.calculate_pde_loss(real_data[\"domain_data\"])\n","\n","        # Calculate total pinn loss\n","        return loss_b + loss_i + loss_pde\n","\n","\n","    def calculate_test_loss(self, test_data):\n","        pde_res = self.calculate_pde_residual(test_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.l1_loss(pde_res, pde_target)\n","\n","\n","    def train_on_real(self, real_data):\n","        loss_real = self.calculate_real_loss(real_data)\n","        loss_real.backward()\n","        return loss_real\n","\n","\n","    def closure(self):\n","        self.lbfgs_optimizer.zero_grad()\n","        return self.train_on_real(self.real_data)"],"metadata":{"id":"GjJ_f5zo63WW","executionInfo":{"status":"ok","timestamp":1711133981417,"user_tz":-120,"elapsed":13,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNERHKrzFCeB"},"source":["## GAN-PINN"]},{"cell_type":"code","source":["class GAN_PINN():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test, N_noise,\n","                 d_layers, d_activation,\n","                 checkpoint_path,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        # Constants\n","        self.checkpoint_path = checkpoint_path\n","        self.device = device\n","        self.dtype = dtype\n","        self.N_noise = N_noise\n","        self.N_test = N_test\n","\n","        # Create real data\n","        self.real_data_init = Data(x_min, x_max,\n","                                   t_min, t_max,\n","                                   Nx_domain, Nt_domain,\n","                                   Nx_init, Nt_bound,\n","                                   N_test,\n","                                   device,\n","                                   dtype)\n","\n","        # Create test data\n","        self.test_data = self.real_data_init.sample_test()\n","\n","        # Create pinn\n","        self.pinn = PINN(d_layers, d_activation, device)\n","\n","\n","    def generate_data(self):\n","        # Create real data\n","        real_data = {}\n","        real_data[\"domain_data\"] = self.real_data_init.sample_domain()\n","        real_data[\"bound_data\"], real_data[\"u_bound\"] = self.real_data_init.sample_boundary()\n","        real_data[\"init_data\"], real_data[\"u_init\"] = self.real_data_init.sample_initial()\n","\n","        return real_data\n","\n","\n","    def train_with_adam(self, N_adam, real_data):\n","        optimizer = self.pinn.optimizers['adam']\n","\n","        for epoch in range(1, N_adam + 1):\n","            optimizer.zero_grad()\n","            loss_D = self.pinn.train_on_real(real_data)\n","            optimizer.step()\n","\n","\n","    def train_with_lbfgs(self, N_lbfgs, real_data):\n","        self.pinn.lbfgs_optimizer = self.pinn.optimizers[\"lbfgs\"]\n","        self.pinn.real_data = real_data\n","\n","        for epoch in range(1, N_lbfgs + 1):\n","            loss_D = self.pinn.lbfgs_optimizer.step(self.pinn.closure)\n","\n","        return loss_D\n","\n","\n","    def checkpoint(self):\n","        torch.save({\n","            \"model\": self.pinn.model.state_dict()\n","        }, self.checkpoint_path)\n","\n","\n","    def format_loss(self, loss):\n","        if loss == 0:\n","            return \"0.0e+00\"\n","\n","        # Calculate the exponent part\n","        exponent = int(math.log10(abs(loss)))\n","\n","        # Determine the format based on the value of the loss\n","        if abs(loss) < 1:\n","            formatted_loss = f\"{loss:.2e}\"\n","        else:\n","            # Adjust the sign of the formatted loss\n","            sign = \"-\" if loss < 0 else \"\"\n","\n","            # Calculate the number of decimal places\n","            decimal_places = 2 - exponent\n","\n","            # Ensure at least two decimal places\n","            decimal_places = max(decimal_places, 2)\n","\n","            # Format the loss with the correct sign\n","            formatted_loss = f\"{sign}{abs(loss):.{decimal_places}e}\"\n","\n","        return formatted_loss\n","\n","\n","    def keep_checkpoints_and_print_losses(self, iter, patience, print_every,\n","                                          loss_D, loss_test):\n","\n","        loss_D_str = self.format_loss(loss_D)\n","        loss_test_str = self.format_loss(loss_test)\n","\n","        if iter == 1:\n","            self.best_val_loss = loss_test\n","            self.best_epoch = -1\n","            self.checkpoint()\n","            self.flag = 1\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","        else:\n","            if loss_test < self.best_val_loss:\n","                self.best_val_loss = loss_test\n","                self.best_epoch = iter\n","                self.checkpoint()\n","                self.flag = 1\n","                if iter % print_every == 0:\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","            elif iter - self.best_epoch > patience:\n","                if iter % print_every == 0:\n","                    self.early_stopping_applied = 1\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | test_mae: {loss_test_str}\")\n","                return\n","\n","        if (self.flag == 0) and (iter % print_every == 0):\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | test_mae: {loss_test_str}\")\n","\n","\n","    def train(self, iters, patience, print_every, N_adam, N_lbfgs):\n","\n","        print(f\"GAN-PINN: {iters} iterations\")\n","        print(f\"a. PINN: {N_adam} epochs --> Adam\")\n","        print(f\"b. PINN: {N_lbfgs} epochs --> L-BFGS\")\n","\n","        for iter in tqdm(range(1, iters + 1)):\n","            self.flag = 0\n","            self.early_stopping_applied = 0\n","\n","            real_data = self.generate_data()\n","\n","            self.train_with_adam(N_adam, real_data)\n","            loss_D = self.train_with_lbfgs(N_lbfgs, real_data)\n","\n","            loss_test = self.pinn.calculate_test_loss(self.test_data)\n","\n","            self.keep_checkpoints_and_print_losses(iter, patience, print_every,\n","                                                   loss_D, loss_test)\n","\n","            if self.early_stopping_applied:\n","                print(f\"\\nEarly stopping applied at epoch {iter}.\")\n","                break"],"metadata":{"id":"hNUssAyw5MMh","executionInfo":{"status":"ok","timestamp":1711133981417,"user_tz":-120,"elapsed":12,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# train_data = gan_pinn.generate_data()\n","# print(train_data.keys())"],"metadata":{"id":"rL2oFR6SeBiE","executionInfo":{"status":"ok","timestamp":1711133996186,"user_tz":-120,"elapsed":3,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# key = 'init_data'\n","# data = train_data[key].detach().cpu().numpy()\n","# print(data.shape)\n","\n","# plt.figure()\n","# plt.scatter(data[:, 0], data[:, 1])\n","# plt.show()"],"metadata":{"id":"thdiSWHleM03","executionInfo":{"status":"ok","timestamp":1711133998851,"user_tz":-120,"elapsed":383,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# key = 'u_init'\n","# data = train_data[key].detach().cpu().numpy().flatten()\n","# print(data.shape)\n","\n","# plt.figure()\n","# plt.plot(np.sort(data))\n","# plt.show()"],"metadata":{"id":"WkIEQrmCfE-K","executionInfo":{"status":"ok","timestamp":1711133999088,"user_tz":-120,"elapsed":2,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"9766h9FaaM_k"}},{"cell_type":"code","source":["# Data\n","x_min, x_max = -1, 1\n","t_min, t_max = 0, 1\n","Nx_domain = 2_500\n","Nt_domain = 2_500\n","Nx_init = 100\n","Nt_bound = 100\n","N_noise = 1_000\n","N_test = 100_000\n","\n","# pinn\n","Nd_layers = 3\n","Nd_neurons = 20\n","d_layers = [2] + Nd_layers * [Nd_neurons] + [1]\n","d_activation = nn.Tanh()\n","\n","# Basic\n","seed = 0\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","checkpoint_path = \"pinn.pth\"\n","dtype = torch.float32\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# GAN-PINN initialization\n","gan_pinn = GAN_PINN(\n","    x_min, x_max,\n","    t_min, t_max,\n","    Nx_domain, Nt_domain,\n","    Nx_init, Nt_bound,\n","    N_test, N_noise,\n","    d_layers, d_activation,\n","    checkpoint_path\n",")\n","\n","# Training\n","iterations = 30\n","patience = iterations\n","print_every = 1\n","num_epochs_adam = 1_000\n","num_epochs_lbfgs = 1\n","\n","gan_pinn.train(iterations, patience, print_every, num_epochs_adam, num_epochs_lbfgs)"],"metadata":{"id":"Mxs5oZzT-PIf","colab":{"base_uri":"https://localhost:8080/","height":701,"referenced_widgets":["12cbdd3e0440421fade9cccc1723450c","2b21b393007d45e288ef0411f57a10a3","ad65f4007dab4b82b8c23a79d502da5c","d29382b1e75c4887b3880f2fb7dce2ef","27f747e6ded9405280801bf9746225c4","ea7afd4ba0164eb1bfbb290bfdb9a2b8","77497726c1804c41a69de1ca47d914f9","69de0318c2e846138d77395a2f154dcf","5ce3ae0f199f45dba22d2984ef19bf23","ebfce7513bee4d768202e440f9a97214","f7188b8e89db419b985d79115c0dcf15"]},"executionInfo":{"status":"error","timestamp":1711134765285,"user_tz":-120,"elapsed":298496,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}},"outputId":"5fd58c01-5d79-4806-a8cc-1850c0458c0a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["GAN-PINN: 30 iterations\n","a. PINN: 1000 epochs --> Adam\n","b. PINN: 1 epochs --> L-BFGS\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12cbdd3e0440421fade9cccc1723450c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Iteration: 1 | loss_D: 1.05e-01 | test_mae: 2.48e-02 - *Checkpoint*\n","Iteration: 2 | loss_D: 2.39e-03 | test_mae: 1.56e-02 - *Checkpoint*\n","Iteration: 3 | loss_D: 8.19e-04 | test_mae: 1.25e-02 - *Checkpoint*\n","Iteration: 4 | loss_D: 2.98e-04 | test_mae: 1.26e-02\n","Iteration: 5 | loss_D: 5.30e-04 | test_mae: 1.18e-02 - *Checkpoint*\n","Iteration: 6 | loss_D: 2.68e-04 | test_mae: 9.14e-03 - *Checkpoint*\n","Iteration: 7 | loss_D: 7.32e-05 | test_mae: 1.31e-02\n","Iteration: 8 | loss_D: 3.99e-04 | test_mae: 8.77e-03 - *Checkpoint*\n","Iteration: 9 | loss_D: 1.59e-04 | test_mae: 1.09e-02\n","Iteration: 10 | loss_D: 1.93e-04 | test_mae: 6.54e-03 - *Checkpoint*\n","Iteration: 11 | loss_D: 7.23e-05 | test_mae: 7.11e-03\n","Iteration: 12 | loss_D: 2.60e-04 | test_mae: 6.64e-03\n","Iteration: 13 | loss_D: 6.94e-05 | test_mae: 7.47e-03\n","Iteration: 14 | loss_D: 1.42e-04 | test_mae: 1.39e-02\n","Iteration: 15 | loss_D: 2.62e-04 | test_mae: 5.53e-03 - *Checkpoint*\n","Iteration: 16 | loss_D: 6.05e-05 | test_mae: 5.27e-03 - *Checkpoint*\n","Iteration: 17 | loss_D: 3.93e-05 | test_mae: 5.13e-03 - *Checkpoint*\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-48a7a02c7f8f>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mnum_epochs_lbfgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mgan_pinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs_lbfgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-297d2bdd593a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iters, patience, print_every, N_adam, N_lbfgs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_adam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_lbfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_test_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-297d2bdd593a>\u001b[0m in \u001b[0;36mtrain_with_lbfgs\u001b[0;34m(self, N_lbfgs, real_data)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_lbfgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbfgs_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                             )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0mal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_stps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}