{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["VOI_YmDXZe-F","gNEEvUazVMr5","TZmOZNCYU4Oz","ZMIEZDwgQ_-N"],"toc_visible":true,"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPjCmMgKO9TX+9BRHr/A5Zv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"878d947e20aa4a7e98734c6654b9656c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72861afb833646ec810fe6a0cde5efc9","IPY_MODEL_df608448f3c54b76814710d7e67528cb","IPY_MODEL_dd4e4049365347aabbe23f20e7253da4"],"layout":"IPY_MODEL_b3b39abde9fa4b2fbc75a8d66da43f19"}},"72861afb833646ec810fe6a0cde5efc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e2c415cb63c4921bd859cf6a84b0fc4","placeholder":"​","style":"IPY_MODEL_b16884607b7d4018bbadb94e38e82732","value":" 83%"}},"df608448f3c54b76814710d7e67528cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9d724c6f1ee47f4b45b1f3ec664afd9","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9a0939fa96c46089b9ced0a1434e2de","value":83}},"dd4e4049365347aabbe23f20e7253da4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bd3aeb649d846b888d5bc7adb0a3ab3","placeholder":"​","style":"IPY_MODEL_83709ae27dbd40248b9371ac343d81bd","value":" 83/100 [29:54&lt;03:44, 13.22s/it]"}},"b3b39abde9fa4b2fbc75a8d66da43f19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e2c415cb63c4921bd859cf6a84b0fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b16884607b7d4018bbadb94e38e82732":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9d724c6f1ee47f4b45b1f3ec664afd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9a0939fa96c46089b9ced0a1434e2de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6bd3aeb649d846b888d5bc7adb0a3ab3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83709ae27dbd40248b9371ac343d81bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"I_M5bLCUymUM"},"source":["# **Burger's equation**:\n","# $ u_t + u u_{xx} = v u_{xx} \\qquad x\\in[-1,1], \\quad t\\in [0,1], \\quad u ≡ u(x,t)$\n","\n","## Boundary conditions (Dirichlet):\n","* $ u(-1, t) = 0, \\qquad t\\in [0,1]$\n","* $ u(1, t) = 0, \\qquad t\\in [0,1]$\n","\n","## Initial condition:\n","* $ u(x, 0) = -\\sin(\\pi x), \\qquad x\\in[-1,1] $\n","\n","<!-- ## *ANALYTICAL SOLUTION*\n","## $ u(x, y, t) = e^{-13\\pi^2t}\\sin(3\\pi x)\\sin(2\\pi y)  $ -->\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VOI_YmDXZe-F"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3D4QbFPZhFL"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"z1DNgf78ZbRR"},"source":["# Helpers"]},{"cell_type":"markdown","metadata":{"id":"gNEEvUazVMr5"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgN6P2ZxVOJS"},"outputs":[],"source":["def generate_random_numbers(min_, max_, N, dtype):\n","    return min_ + (max_ - min_) * torch.rand(size=(N,), dtype=dtype)\n","\n","\n","class Data():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        self.x_min = x_min\n","        self.x_max = x_max\n","        self.t_min = t_min\n","        self.t_max = t_max\n","        self.Nx_domain = Nx_domain\n","        self.Nt_domain = Nt_domain\n","        self.Nx_init = Nx_init\n","        self.Nt_bound = Nt_bound\n","        self.N_test = N_test\n","        self.device = device\n","        self.dtype = dtype\n","\n","\n","    # *** Create in-domain points ***\n","    def sample_domain(self):\n","        # Random Grid\n","        x_domain = generate_random_numbers(self.x_min, self.x_max, self.Nx_domain, self.dtype)\n","        t_domain = generate_random_numbers(self.t_min, self.t_max, self.Nt_domain, self.dtype)\n","        domain_data = torch.stack(torch.meshgrid(x_domain, t_domain)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","        return domain_data\n","\n","    # *** Boundary Conditions ***\n","    def sample_boundary(self):\n","        # Random boundary points\n","        t_bound = generate_random_numbers(self.t_min, self.t_max, self.Nt_bound, self.dtype)\n","        x_left = - torch.ones(1, dtype=self.dtype)\n","        x_right = torch.ones(1, dtype=self.dtype)\n","\n","        bound_data_left = torch.stack(torch.meshgrid(x_left, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data_right = torch.stack(torch.meshgrid(x_right, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data = torch.cat([bound_data_left, bound_data_right]).requires_grad_(True).to(self.device)\n","\n","        u_bound = torch.zeros(len(bound_data), 1, dtype=self.dtype, device=self.device)\n","\n","        return bound_data, u_bound\n","\n","\n","    # *** Initial Condition ***\n","    def sample_initial(self):\n","        # Random initial points\n","        x_init = generate_random_numbers(self.x_min, self.x_max, self.Nx_init, self.dtype)\n","        t_init = torch.zeros(1, dtype=self.dtype)\n","        init_data = torch.stack(torch.meshgrid(x_init, t_init)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","\n","        u_init = - torch.sin(math.pi * x_init)\n","\n","        return init_data, u_init\n","\n","    # *** Test set ***\n","    def sample_test(self):\n","        x_test = self.x_min + (self.x_max - self.x_min) * torch.rand(self.N_test)\n","        t_test = self.t_min + (self.t_max - self.t_min) * torch.rand(self.N_test)\n","        return torch.stack([x_test, t_test], dim=1).requires_grad_(True).to(self.device)"]},{"cell_type":"markdown","metadata":{"id":"TZmOZNCYU4Oz"},"source":["## Networks"]},{"cell_type":"code","source":["class MLPBase(nn.Module):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__()\n","        self.n_layers = len(layers) - 1\n","        self.layers = layers\n","        self.activation = activation\n","        self.weight_init = weight_init\n","        self.bias_init = bias_init\n","\n","        dense_layers = [\n","            self.dense_layer(in_features=self.layers[i], out_features=self.layers[i + 1])\n","            for i in range(self.n_layers - 1)]\n","        dense_layers.append(nn.Linear(in_features=self.layers[-2], out_features=self.layers[-1]))\n","\n","        self.mlp = nn.Sequential(*dense_layers).to(device)\n","\n","    def dense_layer(self, in_features, out_features):\n","        dense_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=out_features),\n","        )\n","\n","        if self.weight_init is not None:\n","            self.weight_init(dense_layer[0].weight)\n","\n","        if self.bias_init is not None:\n","            self.bias_init(dense_layer[0].bias)\n","\n","        dense_layer.add_module(\"activation\", self.activation)\n","        return dense_layer\n","\n","\n","class gMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        g_out = self.mlp(x)\n","        x_out = torch.tanh(g_out[:, 0].clone()).view(-1, 1)\n","        t_out = torch.sigmoid(g_out[:, 1].clone()).view(-1, 1)\n","        return torch.cat((x_out, t_out), dim=1)\n","\n","\n","class dMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n"],"metadata":{"id":"BrYO4dPrrWP9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generator"],"metadata":{"id":"CJoBS0b7Kb6Z"}},{"cell_type":"code","source":["class Generator():\n","    def __init__(self,\n","                 layers,\n","                 activation,\n","                 device):\n","\n","        # Define the model\n","        self.model = gMLP(layers=layers,\n","                          activation=activation,\n","                          weight_init=lambda m: nn.init.xavier_normal_(m.data, nn.init.calculate_gain('tanh')),\n","                          bias_init=lambda m: nn.init.zeros_(m.data),\n","                          device=device)\n","\n","        # Set the optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters())\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def calculate_loss(self, fake_data, discriminator):\n","        pde_res = discriminator.calculate_pde_residual(fake_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return - discriminator.criterion(pde_res, pde_target)\n","\n","\n","    def train(self, fake_data, discriminator):\n","        # \"Zero\" the gradients\n","        self.optimizer.zero_grad()\n","\n","        # Calculate loss\n","        loss = self.calculate_loss(fake_data, discriminator)\n","\n","        # Backpropagate the loss\n","        loss.backward()\n","\n","        # Implement one step of gradient descent\n","        self.optimizer.step()\n","\n","        return loss"],"metadata":{"id":"-YwYgjRW3wzb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Discriminator"],"metadata":{"id":"difNKQa1Kewd"}},{"cell_type":"code","source":["class Discriminator():\n","    def __init__(self,\n","                 layers,\n","                 activation,\n","                 device):\n","\n","        self.v = 0.01 / math.pi\n","\n","        # Define the model\n","        self.model = dMLP(layers=layers,\n","                          activation=activation,\n","                          weight_init=lambda m: nn.init.xavier_normal_(m.data, nn.init.calculate_gain('tanh')),\n","                          bias_init=lambda m: nn.init.zeros_(m.data),\n","                          device=device)\n","\n","        # Set the optimizers\n","        adam = torch.optim.Adam(self.model.parameters())\n","        lbfgs = torch.optim.LBFGS(self.model.parameters(),\n","                                  lr=1,\n","                                  max_iter=250,  # max_iter=2000,\n","                                  max_eval=None,\n","                                  tolerance_grad=1e-07,\n","                                  tolerance_change=1e-09,\n","                                  history_size=100,\n","                                  line_search_fn='strong_wolfe')\n","\n","        self.optimizers = {\"adam\": adam, \"lbfgs\": lbfgs}\n","\n","        # Set the Loss function\n","        self.criterion = nn.MSELoss()\n","\n","        # Set the MAE criterion for test data only\n","        self.l1_loss = nn.L1Loss()\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def grad(self, output, input):\n","        return torch.autograd.grad(\n","                    output, input,\n","                    grad_outputs=torch.ones_like(output),\n","                    retain_graph=True,\n","                    create_graph=True\n","                )[0]\n","\n","\n","    def calculate_pde_residual(self, x):\n","        # Forward pass\n","        u = self.forward(x)\n","\n","        # Calculate 1st and 2nd derivatives\n","        du_dX = self.grad(u, x)\n","        du_dXX = self.grad(du_dX, x)\n","\n","        # Retrieve the partial gradients\n","        du_dt = du_dX[:, 1].flatten()\n","        du_dx = du_dX[:, 0].flatten()\n","        du_dxx = du_dXX[:, 0].flatten()\n","\n","        return du_dt + u.flatten() * du_dx - self.v * du_dxx\n","\n","\n","    def calculate_pde_loss(self, data):\n","        # Calculate the domain loss\n","        pde_res = self.calculate_pde_residual(data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.criterion(pde_res, pde_target)\n","\n","\n","    def calculate_real_loss(self, real_data):\n","        # Calculate boundary loss\n","        loss_b = self.criterion(\n","            self.forward(real_data[\"bound_data\"]).flatten(),\n","            real_data[\"u_bound\"].flatten()\n","        )\n","\n","        # Calculate initial loss\n","        loss_i = self.criterion(\n","            self.forward(real_data[\"init_data\"]).flatten(),\n","            real_data[\"u_init\"].flatten()\n","        )\n","\n","        # Calculate the domain loss\n","        loss_pde = self.calculate_pde_loss(real_data[\"domain_data\"])\n","\n","        # Calculate total discriminator loss\n","        return loss_b + loss_i + loss_pde\n","\n","\n","    def calculate_fake_loss(self, fake_data):\n","        return self.calculate_pde_loss(fake_data)\n","\n","\n","    def calculate_test_loss(self, test_data):\n","        pde_res = self.calculate_pde_residual(test_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.l1_loss(pde_res, pde_target)\n","\n","\n","    def train_on_real(self, real_data):\n","        loss_real = self.calculate_real_loss(real_data)\n","        loss_real.backward()\n","        return loss_real\n","\n","\n","    def train_on_fake(self, fake_data):\n","        loss_fake = self.calculate_fake_loss(fake_data.detach().requires_grad_(True))\n","        loss_fake.backward()\n","        return loss_fake\n","\n","\n","    def closure(self):\n","        self.lbfgs_optimizer.zero_grad()\n","        loss_real = self.train_on_real(self.real_data)\n","        loss_fake = self.train_on_fake(self.fake_data)\n","        return loss_real + loss_fake"],"metadata":{"id":"GjJ_f5zo63WW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNERHKrzFCeB"},"source":["## GAN-PINN"]},{"cell_type":"code","source":["class GAN_PINN():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test, N_noise,\n","                 g_layers, g_activation,\n","                 d_layers, d_activation,\n","                 checkpoint_path,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        # Constants\n","        self.checkpoint_path = checkpoint_path\n","        self.device = device\n","        self.dtype = dtype\n","        self.N_noise = N_noise\n","        self.N_test = N_test\n","\n","        # Create real data\n","        self.real_data_init = Data(x_min, x_max,\n","                                   t_min, t_max,\n","                                   Nx_domain, Nt_domain,\n","                                   Nx_init, Nt_bound,\n","                                   N_test,\n","                                   device,\n","                                   dtype)\n","\n","        # Create test data\n","        self.test_data = self.real_data_init.sample_test()\n","\n","        # Create Generator\n","        self.generator = Generator(g_layers, g_activation, device)\n","\n","        # Create Discriminator\n","        self.discriminator = Discriminator(d_layers, d_activation, device)\n","\n","\n","    def generate_data(self):\n","        # Create real data\n","        real_data = {}\n","        real_data[\"domain_data\"] = self.real_data_init.sample_domain()\n","        real_data[\"bound_data\"], real_data[\"u_bound\"] = self.real_data_init.sample_boundary()\n","        real_data[\"init_data\"], real_data[\"u_init\"] = self.real_data_init.sample_initial()\n","\n","        # Create noise (Generator's input)\n","        random_tensor = torch.rand(self.N_noise, 2)  # 2 refers to (x, t)\n","        x_noise = 2 * random_tensor[:, 0] - 1\n","        t_noise = random_tensor[:, 1]\n","        noise = torch.cat((x_noise.view(-1, 1), t_noise.view(-1, 1)), dim=1)\n","\n","        return real_data, noise\n","\n","\n","    def train_with_adam(self, N_adam, real_data, fake_data):\n","        optimizer = self.discriminator.optimizers['adam']\n","\n","        for epoch in range(1, N_adam + 1):\n","            optimizer.zero_grad()\n","            loss_real = self.discriminator.train_on_real(real_data)\n","            loss_fake = self.discriminator.train_on_fake(fake_data)\n","            loss_D = loss_real + loss_fake\n","            optimizer.step()\n","\n","\n","    def train_with_lbfgs(self, N_lbfgs, real_data, fake_data):\n","        self.discriminator.lbfgs_optimizer = self.discriminator.optimizers[\"lbfgs\"]\n","        self.discriminator.real_data = real_data\n","        self.discriminator.fake_data = fake_data\n","\n","        for epoch in range(1, N_lbfgs + 1):\n","            loss_D = self.discriminator.lbfgs_optimizer.step(self.discriminator.closure)\n","\n","        return loss_D\n","\n","\n","    def checkpoint(self):\n","        torch.save({\n","            \"model\": self.discriminator.model.state_dict()\n","        }, self.checkpoint_path)\n","\n","\n","    def format_loss(self, loss):\n","        if loss == 0:\n","            return \"0.0e+00\"\n","\n","        # Calculate the exponent part\n","        exponent = int(math.log10(abs(loss)))\n","\n","        # Determine the format based on the value of the loss\n","        if abs(loss) < 1:\n","            formatted_loss = f\"{loss:.2e}\"\n","        else:\n","            # Adjust the sign of the formatted loss\n","            sign = \"-\" if loss < 0 else \"\"\n","\n","            # Calculate the number of decimal places\n","            decimal_places = 2 - exponent\n","\n","            # Ensure at least two decimal places\n","            decimal_places = max(decimal_places, 2)\n","\n","            # Format the loss with the correct sign\n","            formatted_loss = f\"{sign}{abs(loss):.{decimal_places}e}\"\n","\n","        return formatted_loss\n","\n","\n","    def keep_checkpoints_and_print_losses(self, iter, patience, print_every,\n","                                          loss_D, loss_G, loss_test):\n","\n","        loss_D_str = self.format_loss(loss_D)\n","        loss_G_str = self.format_loss(loss_G)\n","        loss_test_str = self.format_loss(loss_test)\n","\n","        if iter == 1:\n","            self.best_val_loss = loss_test\n","            self.best_epoch = -1\n","            self.checkpoint()\n","            self.flag = 1\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","        else:\n","            if loss_test < self.best_val_loss:\n","                self.best_val_loss = loss_test\n","                self.best_epoch = iter\n","                self.checkpoint()\n","                self.flag = 1\n","                if iter % print_every == 0:\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","            elif iter - self.best_epoch > patience:\n","                if iter % print_every == 0:\n","                    self.early_stopping_applied = 1\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str}\")\n","                return\n","\n","        if (self.flag == 0) and (iter % print_every == 0):\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str}\")\n","\n","\n","    def train(self, iters, patience, print_every, N_adam, N_lbfgs):\n","\n","        print(f\"GAN-PINN: {iters} iterations\")\n","        print(f\"a. PINN: {N_adam} epochs --> Adam\")\n","        print(f\"b. PINN: {N_lbfgs} epochs --> L-BFGS\")\n","        print(f\"c. Generator: 1 epoch --> Adam\\n\")\n","\n","        for iter in tqdm(range(1, iters + 1)):\n","            self.flag = 0\n","            self.early_stopping_applied = 0\n","\n","            real_data, noise = self.generate_data()\n","            fake_data = self.generator.model(noise)\n","\n","            self.train_with_adam(N_adam, real_data, fake_data)\n","            loss_D = self.train_with_lbfgs(N_lbfgs, real_data, fake_data)\n","            loss_G = self.generator.train(fake_data, self.discriminator)\n","\n","            loss_test = self.discriminator.calculate_test_loss(self.test_data)\n","\n","            self.keep_checkpoints_and_print_losses(iter, patience, print_every,\n","                                                   loss_D, loss_G, loss_test)\n","\n","            if self.early_stopping_applied:\n","                print(f\"\\nEarly stopping applied at epoch {iter}.\")\n","                break"],"metadata":{"id":"hNUssAyw5MMh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"9766h9FaaM_k"}},{"cell_type":"code","source":["# Data\n","x_min, x_max = -1, 1\n","t_min, t_max = 0, 1\n","Nx_domain = 200\n","Nt_domain = 100\n","Nx_init = 100\n","Nt_bound = 100\n","N_noise = 1_000\n","N_test = 100_000\n","\n","# Generator\n","Ng_layers = 3\n","Ng_neurons = 64\n","g_layers = [2] + Ng_layers * [Ng_neurons] + [2]\n","g_activation = nn.Tanh()\n","\n","# Discriminator\n","Nd_layers = 3\n","Nd_neurons = 20\n","d_layers = [2] + Nd_layers * [Nd_neurons] + [1]\n","d_activation = nn.Tanh()\n","\n","# Other\n","checkpoint_path = \"discriminator.pth\"\n","dtype = torch.float32\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# GAN-PINN initialization\n","gan_pinn = GAN_PINN(\n","    x_min, x_max,\n","    t_min, t_max,\n","    Nx_domain, Nt_domain,\n","    Nx_init, Nt_bound,\n","    N_test, N_noise,\n","    g_layers, g_activation,\n","    d_layers, d_activation,\n","    checkpoint_path\n",")\n","\n","# Training\n","iterations = 100\n","patience = 10\n","print_every = 1\n","num_epochs_adam = 20\n","num_epochs_lbfgs = 5\n","\n","gan_pinn.train(iterations, patience, print_every, num_epochs_adam, num_epochs_lbfgs)"],"metadata":{"id":"Mxs5oZzT-PIf","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["878d947e20aa4a7e98734c6654b9656c","72861afb833646ec810fe6a0cde5efc9","df608448f3c54b76814710d7e67528cb","dd4e4049365347aabbe23f20e7253da4","b3b39abde9fa4b2fbc75a8d66da43f19","8e2c415cb63c4921bd859cf6a84b0fc4","b16884607b7d4018bbadb94e38e82732","c9d724c6f1ee47f4b45b1f3ec664afd9","d9a0939fa96c46089b9ced0a1434e2de","6bd3aeb649d846b888d5bc7adb0a3ab3","83709ae27dbd40248b9371ac343d81bd"]},"executionInfo":{"status":"ok","timestamp":1709740143731,"user_tz":-120,"elapsed":1796583,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}},"outputId":"7dcd605e-a187-403a-cfcc-5e109aebc039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GAN-PINN: 100 iterations\n","a. PINN: 20 epochs --> Adam\n","b. PINN: 5 epochs --> L-BFGS\n","c. Generator: 1 epoch --> Adam\n","\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"878d947e20aa4a7e98734c6654b9656c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Iteration: 1 | loss_D: 1.77e-02 | loss_G: -9.12e-04 | test_mae: 5.63e-02 - *Checkpoint*\n","Iteration: 2 | loss_D: 8.32e-03 | loss_G: -5.43e-04 | test_mae: 4.97e-02 - *Checkpoint*\n","Iteration: 3 | loss_D: 7.16e-03 | loss_G: -2.61e-04 | test_mae: 3.90e-02 - *Checkpoint*\n","Iteration: 4 | loss_D: 3.81e-03 | loss_G: -2.21e-04 | test_mae: 2.90e-02 - *Checkpoint*\n","Iteration: 5 | loss_D: 1.83e-03 | loss_G: -2.17e-04 | test_mae: 2.65e-02 - *Checkpoint*\n","Iteration: 6 | loss_D: 1.64e-03 | loss_G: -1.76e-04 | test_mae: 2.72e-02\n","Iteration: 7 | loss_D: 1.11e-03 | loss_G: -1.07e-04 | test_mae: 3.82e-02\n","Iteration: 8 | loss_D: 2.44e-02 | loss_G: -4.58e-03 | test_mae: 4.14e-02\n","Iteration: 9 | loss_D: 1.09e-03 | loss_G: -1.17e-04 | test_mae: 4.04e-02\n","Iteration: 10 | loss_D: 9.70e-04 | loss_G: -7.67e-05 | test_mae: 2.37e-02 - *Checkpoint*\n","Iteration: 11 | loss_D: 8.62e-04 | loss_G: -4.63e-05 | test_mae: 4.27e-02\n","Iteration: 12 | loss_D: 7.10e-04 | loss_G: -6.04e-05 | test_mae: 1.94e-02 - *Checkpoint*\n","Iteration: 13 | loss_D: 1.07e-03 | loss_G: -4.76e-05 | test_mae: 1.42e-02 - *Checkpoint*\n","Iteration: 14 | loss_D: 8.86e-04 | loss_G: -3.65e-05 | test_mae: 2.08e-02\n","Iteration: 15 | loss_D: 6.30e-04 | loss_G: -3.19e-05 | test_mae: 1.57e-02\n","Iteration: 16 | loss_D: 9.44e-04 | loss_G: -2.46e-05 | test_mae: 1.50e-02\n","Iteration: 17 | loss_D: 1.14e-03 | loss_G: -3.89e-05 | test_mae: 1.56e-02\n","Iteration: 18 | loss_D: 4.30e-04 | loss_G: -4.19e-05 | test_mae: 1.24e-02 - *Checkpoint*\n","Iteration: 19 | loss_D: 2.64e-04 | loss_G: -2.38e-05 | test_mae: 1.28e-02\n","Iteration: 20 | loss_D: 2.04e-04 | loss_G: -2.34e-05 | test_mae: 1.35e-02\n","Iteration: 21 | loss_D: 3.49e-04 | loss_G: -3.81e-05 | test_mae: 1.29e-02\n","Iteration: 22 | loss_D: 3.76e-04 | loss_G: -3.22e-05 | test_mae: 1.16e-02 - *Checkpoint*\n","Iteration: 23 | loss_D: 2.43e-04 | loss_G: -2.72e-05 | test_mae: 1.17e-02\n","Iteration: 24 | loss_D: 3.20e-04 | loss_G: -3.93e-05 | test_mae: 1.03e-02 - *Checkpoint*\n","Iteration: 25 | loss_D: 4.92e-04 | loss_G: -3.76e-05 | test_mae: 1.09e-02\n","Iteration: 26 | loss_D: 2.59e-04 | loss_G: -5.44e-05 | test_mae: 1.16e-02\n","Iteration: 27 | loss_D: 2.66e-04 | loss_G: -2.77e-05 | test_mae: 1.14e-02\n","Iteration: 28 | loss_D: 3.66e-04 | loss_G: -4.05e-05 | test_mae: 9.05e-03 - *Checkpoint*\n","Iteration: 29 | loss_D: 2.09e-04 | loss_G: -1.39e-05 | test_mae: 9.95e-03\n","Iteration: 30 | loss_D: 1.98e-04 | loss_G: -2.29e-05 | test_mae: 1.09e-02\n","Iteration: 31 | loss_D: 1.96e-04 | loss_G: -2.06e-05 | test_mae: 9.97e-03\n","Iteration: 32 | loss_D: 2.65e-04 | loss_G: -2.80e-05 | test_mae: 9.87e-03\n","Iteration: 33 | loss_D: 1.98e-04 | loss_G: -2.03e-05 | test_mae: 8.72e-03 - *Checkpoint*\n","Iteration: 34 | loss_D: 1.36e-04 | loss_G: -1.69e-05 | test_mae: 1.07e-02\n","Iteration: 35 | loss_D: 1.73e-04 | loss_G: -1.29e-05 | test_mae: 1.04e-02\n","Iteration: 36 | loss_D: 9.73e-05 | loss_G: -9.02e-06 | test_mae: 1.39e-02\n","Iteration: 37 | loss_D: 1.26e-04 | loss_G: -7.50e-06 | test_mae: 9.89e-03\n","Iteration: 38 | loss_D: 2.57e-04 | loss_G: -2.02e-05 | test_mae: 9.02e-03\n","Iteration: 39 | loss_D: 1.29e-04 | loss_G: -1.19e-05 | test_mae: 1.03e-02\n","Iteration: 40 | loss_D: 1.13e-04 | loss_G: -6.08e-06 | test_mae: 8.69e-03 - *Checkpoint*\n","Iteration: 41 | loss_D: 2.27e-04 | loss_G: -3.38e-05 | test_mae: 8.95e-03\n","Iteration: 42 | loss_D: 2.53e-04 | loss_G: -2.13e-05 | test_mae: 8.54e-03 - *Checkpoint*\n","Iteration: 43 | loss_D: 3.00e-04 | loss_G: -2.79e-05 | test_mae: 7.78e-03 - *Checkpoint*\n","Iteration: 44 | loss_D: 1.80e-04 | loss_G: -1.97e-05 | test_mae: 7.92e-03\n","Iteration: 45 | loss_D: 2.21e-04 | loss_G: -2.14e-05 | test_mae: 7.34e-03 - *Checkpoint*\n","Iteration: 46 | loss_D: 1.67e-04 | loss_G: -1.56e-05 | test_mae: 9.73e-03\n","Iteration: 47 | loss_D: 1.71e-04 | loss_G: -1.55e-05 | test_mae: 8.25e-03\n","Iteration: 48 | loss_D: 1.60e-04 | loss_G: -8.09e-06 | test_mae: 9.06e-03\n","Iteration: 49 | loss_D: 2.57e-04 | loss_G: -2.41e-05 | test_mae: 8.50e-03\n","Iteration: 50 | loss_D: 2.08e-04 | loss_G: -1.75e-05 | test_mae: 9.20e-03\n","Iteration: 51 | loss_D: 2.26e-04 | loss_G: -1.40e-05 | test_mae: 7.02e-03 - *Checkpoint*\n","Iteration: 52 | loss_D: 1.14e-04 | loss_G: -7.01e-06 | test_mae: 9.62e-03\n","Iteration: 53 | loss_D: 1.13e-04 | loss_G: -1.87e-05 | test_mae: 8.14e-03\n","Iteration: 54 | loss_D: 1.31e-04 | loss_G: -1.58e-05 | test_mae: 9.27e-03\n","Iteration: 55 | loss_D: 2.04e-04 | loss_G: -1.96e-05 | test_mae: 7.73e-03\n","Iteration: 56 | loss_D: 9.91e-05 | loss_G: -1.07e-05 | test_mae: 8.48e-03\n","Iteration: 57 | loss_D: 2.15e-04 | loss_G: -3.61e-05 | test_mae: 6.81e-03 - *Checkpoint*\n","Iteration: 58 | loss_D: 1.36e-04 | loss_G: -9.13e-06 | test_mae: 9.30e-03\n","Iteration: 59 | loss_D: 1.99e-04 | loss_G: -2.23e-05 | test_mae: 7.63e-03\n","Iteration: 60 | loss_D: 1.41e-04 | loss_G: -7.70e-06 | test_mae: 9.56e-03\n","Iteration: 61 | loss_D: 8.48e-05 | loss_G: -4.63e-06 | test_mae: 7.42e-03\n","Iteration: 62 | loss_D: 6.79e-05 | loss_G: -5.33e-06 | test_mae: 8.89e-03\n","Iteration: 63 | loss_D: 1.05e-04 | loss_G: -1.25e-05 | test_mae: 9.57e-03\n","Iteration: 64 | loss_D: 1.02e-04 | loss_G: -5.23e-06 | test_mae: 7.59e-03\n","Iteration: 65 | loss_D: 1.09e-04 | loss_G: -1.23e-05 | test_mae: 9.70e-03\n","Iteration: 66 | loss_D: 1.60e-04 | loss_G: -1.12e-05 | test_mae: 7.55e-03\n","Iteration: 67 | loss_D: 1.46e-04 | loss_G: -9.45e-06 | test_mae: 6.22e-03 - *Checkpoint*\n","Iteration: 68 | loss_D: 2.19e-04 | loss_G: -2.77e-05 | test_mae: 6.61e-03\n","Iteration: 69 | loss_D: 2.08e-04 | loss_G: -1.36e-05 | test_mae: 6.44e-03\n","Iteration: 70 | loss_D: 8.00e-05 | loss_G: -7.48e-06 | test_mae: 8.39e-03\n","Iteration: 71 | loss_D: 1.33e-04 | loss_G: -1.55e-05 | test_mae: 7.73e-03\n","Iteration: 72 | loss_D: 5.30e-05 | loss_G: -4.11e-06 | test_mae: 7.43e-03\n","Iteration: 73 | loss_D: 1.54e-04 | loss_G: -1.07e-05 | test_mae: 5.97e-03 - *Checkpoint*\n","Iteration: 74 | loss_D: 6.09e-05 | loss_G: -7.49e-06 | test_mae: 7.89e-03\n","Iteration: 75 | loss_D: 6.72e-05 | loss_G: -5.56e-06 | test_mae: 8.93e-03\n","Iteration: 76 | loss_D: 5.47e-05 | loss_G: -3.81e-06 | test_mae: 8.66e-03\n","Iteration: 77 | loss_D: 8.88e-05 | loss_G: -8.84e-06 | test_mae: 6.08e-03\n","Iteration: 78 | loss_D: 1.28e-04 | loss_G: -1.08e-05 | test_mae: 7.40e-03\n","Iteration: 79 | loss_D: 3.92e-05 | loss_G: -5.08e-06 | test_mae: 1.38e-02\n","Iteration: 80 | loss_D: 1.10e-04 | loss_G: -8.36e-06 | test_mae: 1.00e-02\n","Iteration: 81 | loss_D: 9.30e-05 | loss_G: -9.55e-06 | test_mae: 7.93e-03\n","Iteration: 82 | loss_D: 4.75e-05 | loss_G: -6.80e-06 | test_mae: 1.22e-02\n","Iteration: 83 | loss_D: 2.66e-03 | loss_G: -6.00e-04 | test_mae: 1.58e-02\n","Iteration: 84 | loss_D: 1.39e-04 | loss_G: -1.48e-05 | test_mae: 7.68e-03\n","\n","Early stopping applied at epoch 84.\n"]}]}]}