{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPDuJPkYL4VhTOCjRTNWXiR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f099a7910e3d49c1b86f94c42e49a137":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cae9659eff104d4d968ef37f00c1e681","IPY_MODEL_7054cdb97e5b4c74925c28a03bd337d0","IPY_MODEL_0c15bd3fee30414d9cf3b33fc3a417e4"],"layout":"IPY_MODEL_266f3aeeac9b49daacc058868da37db0"}},"cae9659eff104d4d968ef37f00c1e681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f684665812554899ba21a9d048240d4f","placeholder":"​","style":"IPY_MODEL_a419a46a32c44916afcf6ba454222798","value":"  9%"}},"7054cdb97e5b4c74925c28a03bd337d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_be3f29da0cfb465f8c260d30278c8a59","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6696fdb156e443039f0311d6a36a0926","value":9}},"0c15bd3fee30414d9cf3b33fc3a417e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5989222a2ebc444f84585967b7f4bcde","placeholder":"​","style":"IPY_MODEL_e0516bc5d49244409df1905c4f3c3130","value":" 9/100 [00:26&lt;03:54,  2.58s/it]"}},"266f3aeeac9b49daacc058868da37db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f684665812554899ba21a9d048240d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a419a46a32c44916afcf6ba454222798":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be3f29da0cfb465f8c260d30278c8a59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6696fdb156e443039f0311d6a36a0926":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5989222a2ebc444f84585967b7f4bcde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0516bc5d49244409df1905c4f3c3130":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"I_M5bLCUymUM"},"source":["# **Burger's equation**:\n","# $ u_t + u u_{xx} = v u_{xx} \\qquad x\\in[-1,1], \\quad t\\in [0,1], \\quad u ≡ u(x,t)$\n","\n","## Boundary conditions (Dirichlet):\n","* $ u(-1, t) = 0, \\qquad t\\in [0,1]$\n","* $ u(1, t) = 0, \\qquad t\\in [0,1]$\n","\n","## Initial condition:\n","* $ u(x, 0) = -\\sin(\\pi x), \\qquad x\\in[-1,1] $\n","\n","<!-- ## *ANALYTICAL SOLUTION*\n","## $ u(x, y, t) = e^{-13\\pi^2t}\\sin(3\\pi x)\\sin(2\\pi y)  $ -->\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VOI_YmDXZe-F"},"source":["# Imports"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"X3D4QbFPZhFL","executionInfo":{"status":"ok","timestamp":1710357787622,"user_tz":-120,"elapsed":516,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"z1DNgf78ZbRR"},"source":["# Helpers"]},{"cell_type":"markdown","metadata":{"id":"gNEEvUazVMr5"},"source":["## Data"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TgN6P2ZxVOJS","executionInfo":{"status":"ok","timestamp":1710357788462,"user_tz":-120,"elapsed":10,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"outputs":[],"source":["def generate_random_numbers(min_, max_, N, dtype):\n","    return min_ + (max_ - min_) * torch.rand(size=(N,), dtype=dtype)\n","\n","\n","class Data():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        self.x_min = x_min\n","        self.x_max = x_max\n","        self.t_min = t_min\n","        self.t_max = t_max\n","        self.Nx_domain = Nx_domain\n","        self.Nt_domain = Nt_domain\n","        self.Nx_init = Nx_init\n","        self.Nt_bound = Nt_bound\n","        self.N_test = N_test\n","        self.device = device\n","        self.dtype = dtype\n","\n","\n","    # *** Create in-domain points ***\n","    def sample_domain(self):\n","        # Random Grid\n","        x_domain = generate_random_numbers(self.x_min, self.x_max, self.Nx_domain, self.dtype)\n","        t_domain = generate_random_numbers(self.t_min, self.t_max, self.Nt_domain, self.dtype)\n","        domain_data = torch.stack(torch.meshgrid(x_domain, t_domain)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","        return domain_data\n","\n","    # *** Boundary Conditions ***\n","    def sample_boundary(self):\n","        # Random boundary points\n","        t_bound = generate_random_numbers(self.t_min, self.t_max, self.Nt_bound, self.dtype)\n","        x_left = - torch.ones(1, dtype=self.dtype)\n","        x_right = torch.ones(1, dtype=self.dtype)\n","\n","        bound_data_left = torch.stack(torch.meshgrid(x_left, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data_right = torch.stack(torch.meshgrid(x_right, t_bound)).view(2, -1).permute(1, 0)\n","        bound_data = torch.cat([bound_data_left, bound_data_right]).requires_grad_(True).to(self.device)\n","\n","        u_bound = torch.zeros(len(bound_data), 1, dtype=self.dtype, device=self.device)\n","\n","        return bound_data, u_bound\n","\n","\n","    # *** Initial Condition ***\n","    def sample_initial(self):\n","        # Random initial points\n","        x_init = generate_random_numbers(self.x_min, self.x_max, self.Nx_init, self.dtype)\n","        t_init = torch.zeros(1, dtype=self.dtype)\n","        init_data = torch.stack(torch.meshgrid(x_init, t_init)).view(2, -1).permute(1, 0).requires_grad_(True).to(self.device)\n","\n","        u_init = - torch.sin(math.pi * x_init)\n","\n","        return init_data, u_init\n","\n","    # *** Test set ***\n","    def sample_test(self):\n","        x_test = self.x_min + (self.x_max - self.x_min) * torch.rand(self.N_test)\n","        t_test = self.t_min + (self.t_max - self.t_min) * torch.rand(self.N_test)\n","        return torch.stack([x_test, t_test], dim=1).requires_grad_(True).to(self.device)"]},{"cell_type":"markdown","metadata":{"id":"TZmOZNCYU4Oz"},"source":["## Networks"]},{"cell_type":"code","source":["class MLPBase(nn.Module):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__()\n","        self.n_layers = len(layers) - 1\n","        self.layers = layers\n","        self.activation = activation\n","        self.weight_init = weight_init\n","        self.bias_init = bias_init\n","\n","        dense_layers = [\n","            self.dense_layer(in_features=self.layers[i], out_features=self.layers[i + 1])\n","            for i in range(self.n_layers - 1)]\n","        dense_layers.append(nn.Linear(in_features=self.layers[-2], out_features=self.layers[-1]))\n","\n","        self.mlp = nn.Sequential(*dense_layers).to(device)\n","\n","    def dense_layer(self, in_features, out_features):\n","        dense_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=out_features),\n","        )\n","\n","        if self.weight_init is not None:\n","            self.weight_init(dense_layer[0].weight)\n","\n","        if self.bias_init is not None:\n","            self.bias_init(dense_layer[0].bias)\n","\n","        dense_layer.add_module(\"activation\", self.activation)\n","        return dense_layer\n","\n","\n","class gMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        g_out = self.mlp(x)\n","        x_out = torch.tanh(g_out[:, 0].clone()).view(-1, 1)\n","        t_out = torch.sigmoid(g_out[:, 1].clone()).view(-1, 1)\n","        return torch.cat((x_out, t_out), dim=1)\n","\n","\n","class dMLP(MLPBase):\n","    def __init__(self, layers, activation=nn.Tanh(), weight_init=None, bias_init=None, device='cpu'):\n","        super().__init__(layers, activation, weight_init, bias_init, device)\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n"],"metadata":{"id":"BrYO4dPrrWP9","executionInfo":{"status":"ok","timestamp":1710357788462,"user_tz":-120,"elapsed":9,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Generator"],"metadata":{"id":"CJoBS0b7Kb6Z"}},{"cell_type":"code","source":["class Generator():\n","    def __init__(self,\n","                 layers,\n","                 activation,\n","                 device):\n","\n","        # Define the model\n","        self.model = gMLP(layers=layers,\n","                          activation=activation,\n","                          weight_init=lambda m: nn.init.xavier_normal_(m.data, nn.init.calculate_gain('tanh')),\n","                          bias_init=lambda m: nn.init.zeros_(m.data),\n","                          device=device)\n","\n","        # Set the optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters())\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def calculate_loss(self, fake_data, discriminator):\n","        pde_res = discriminator.calculate_pde_residual(fake_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return - discriminator.criterion(pde_res, pde_target)\n","\n","\n","    def train(self, fake_data, discriminator):\n","        # \"Zero\" the gradients\n","        self.optimizer.zero_grad()\n","\n","        # Calculate loss\n","        loss = self.calculate_loss(fake_data, discriminator)\n","\n","        # Backpropagate the loss\n","        loss.backward()\n","\n","        # Implement one step of gradient descent\n","        self.optimizer.step()\n","\n","        return loss"],"metadata":{"id":"-YwYgjRW3wzb","executionInfo":{"status":"ok","timestamp":1710357788463,"user_tz":-120,"elapsed":10,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Discriminator"],"metadata":{"id":"difNKQa1Kewd"}},{"cell_type":"code","source":["class Discriminator():\n","    def __init__(self,\n","                 layers,\n","                 activation,\n","                 device):\n","\n","        self.v = 0.01 / math.pi\n","\n","        # Define the model\n","        self.model = dMLP(layers=layers,\n","                          activation=activation,\n","                          weight_init=lambda m: nn.init.xavier_normal_(m.data, nn.init.calculate_gain('tanh')),\n","                          bias_init=lambda m: nn.init.zeros_(m.data),\n","                          device=device)\n","\n","        # Set the optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters())\n","\n","        # Set the Loss function\n","        self.criterion = nn.MSELoss()\n","\n","        # Set the MAE criterion for test data only\n","        self.l1_loss = nn.L1Loss()\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","    def grad(self, output, input):\n","        return torch.autograd.grad(\n","                    output, input,\n","                    grad_outputs=torch.ones_like(output),\n","                    retain_graph=True,\n","                    create_graph=True\n","                )[0]\n","\n","\n","    def calculate_pde_residual(self, x):\n","        # Forward pass\n","        u = self.forward(x)\n","\n","        # Calculate 1st and 2nd derivatives\n","        du_dX = self.grad(u, x)\n","        du_dXX = self.grad(du_dX, x)\n","\n","        # Retrieve the partial gradients\n","        du_dt = du_dX[:, 1].flatten()\n","        du_dx = du_dX[:, 0].flatten()\n","        du_dxx = du_dXX[:, 0].flatten()\n","\n","        return du_dt + u.flatten() * du_dx - self.v * du_dxx\n","\n","\n","    def calculate_pde_loss(self, data):\n","        # Calculate the domain loss\n","        pde_res = self.calculate_pde_residual(data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.criterion(pde_res, pde_target)\n","\n","\n","    def calculate_real_loss(self, real_data):\n","        # Calculate boundary loss\n","        loss_b = self.criterion(\n","            self.forward(real_data[\"bound_data\"]).flatten(),\n","            real_data[\"u_bound\"].flatten()\n","        )\n","\n","        # Calculate initial loss\n","        loss_i = self.criterion(\n","            self.forward(real_data[\"init_data\"]).flatten(),\n","            real_data[\"u_init\"].flatten()\n","        )\n","\n","        # Calculate the domain loss\n","        loss_pde = self.calculate_pde_loss(real_data[\"domain_data\"])\n","\n","        # Calculate total discriminator loss\n","        return loss_b + loss_i + loss_pde\n","\n","\n","    def calculate_fake_loss(self, fake_data):\n","        return self.calculate_pde_loss(fake_data)\n","\n","\n","    def calculate_test_loss(self, test_data):\n","        pde_res = self.calculate_pde_residual(test_data)\n","        pde_target = torch.zeros_like(pde_res)\n","        return self.l1_loss(pde_res, pde_target)\n","\n","\n","    def train_on_real(self, real_data):\n","        loss_real = self.calculate_real_loss(real_data)\n","        loss_real.backward()\n","        return loss_real\n","\n","\n","    def train_on_fake(self, fake_data):\n","        loss_fake = self.calculate_fake_loss(fake_data.detach().requires_grad_(True))\n","        loss_fake.backward()\n","        return loss_fake"],"metadata":{"id":"GjJ_f5zo63WW","executionInfo":{"status":"ok","timestamp":1710357788463,"user_tz":-120,"elapsed":9,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNERHKrzFCeB"},"source":["## GAN-PINN"]},{"cell_type":"code","source":["class GAN_PINN():\n","    def __init__(self,\n","                 x_min, x_max,\n","                 t_min, t_max,\n","                 Nx_domain, Nt_domain,\n","                 Nx_init, Nt_bound,\n","                 N_test, N_noise,\n","                 g_layers, g_activation,\n","                 d_layers, d_activation,\n","                 checkpoint_path,\n","                 device='cpu',\n","                 dtype=torch.float32):\n","\n","        # Constants\n","        self.checkpoint_path = checkpoint_path\n","        self.device = device\n","        self.dtype = dtype\n","        self.N_noise = N_noise\n","        self.N_test = N_test\n","\n","        # Create real data\n","        self.real_data_init = Data(x_min, x_max,\n","                                   t_min, t_max,\n","                                   Nx_domain, Nt_domain,\n","                                   Nx_init, Nt_bound,\n","                                   N_test,\n","                                   device,\n","                                   dtype)\n","\n","        # Create test data\n","        self.test_data = self.real_data_init.sample_test()\n","\n","        # Create Generator\n","        self.generator = Generator(g_layers, g_activation, device)\n","\n","        # Create Discriminator\n","        self.discriminator = Discriminator(d_layers, d_activation, device)\n","\n","\n","    def generate_data(self):\n","        # Create real data\n","        real_data = {}\n","        real_data[\"domain_data\"] = self.real_data_init.sample_domain()\n","        real_data[\"bound_data\"], real_data[\"u_bound\"] = self.real_data_init.sample_boundary()\n","        real_data[\"init_data\"], real_data[\"u_init\"] = self.real_data_init.sample_initial()\n","\n","        # Create noise (Generator's input)\n","        random_tensor = torch.rand(self.N_noise, 2)  # 2 refers to (x, t)\n","        x_noise = 2 * random_tensor[:, 0] - 1\n","        t_noise = random_tensor[:, 1]\n","        noise = torch.cat((x_noise.view(-1, 1), t_noise.view(-1, 1)), dim=1)\n","\n","        return real_data, noise\n","\n","\n","    def train_step(self, N, real_data, fake_data):\n","        for epoch in range(1, N + 1):\n","            self.discriminator.optimizer.zero_grad()\n","            loss_real = self.discriminator.train_on_real(real_data)\n","            loss_fake = self.discriminator.train_on_fake(fake_data)\n","            loss_D = loss_real + loss_fake\n","            self.discriminator.optimizer.step()\n","\n","        return loss_D\n","\n","\n","    def checkpoint(self):\n","        torch.save({\n","            \"model\": self.discriminator.model.state_dict()\n","        }, self.checkpoint_path)\n","\n","\n","    def format_loss(self, loss):\n","        if loss == 0:\n","            return \"0.0e+00\"\n","\n","        # Calculate the exponent part\n","        exponent = int(math.log10(abs(loss)))\n","\n","        # Determine the format based on the value of the loss\n","        if abs(loss) < 1:\n","            formatted_loss = f\"{loss:.2e}\"\n","        else:\n","            # Adjust the sign of the formatted loss\n","            sign = \"-\" if loss < 0 else \"\"\n","\n","            # Calculate the number of decimal places\n","            decimal_places = 2 - exponent\n","\n","            # Ensure at least two decimal places\n","            decimal_places = max(decimal_places, 2)\n","\n","            # Format the loss with the correct sign\n","            formatted_loss = f\"{sign}{abs(loss):.{decimal_places}e}\"\n","\n","        return formatted_loss\n","\n","\n","    def keep_checkpoints_and_print_losses(self, iter, patience, print_every,\n","                                          loss_D, loss_G, loss_test):\n","\n","        loss_D_str = self.format_loss(loss_D)\n","        loss_G_str = self.format_loss(loss_G)\n","        loss_test_str = self.format_loss(loss_test)\n","\n","        if iter == 1:\n","            self.best_val_loss = loss_test\n","            self.best_epoch = -1\n","            self.checkpoint()\n","            self.flag = 1\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","        else:\n","            if loss_test < self.best_val_loss:\n","                self.best_val_loss = loss_test\n","                self.best_epoch = iter\n","                self.checkpoint()\n","                self.flag = 1\n","                if iter % print_every == 0:\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str} - *Checkpoint*\")\n","            elif iter - self.best_epoch > patience:\n","                if iter % print_every == 0:\n","                    self.early_stopping_applied = 1\n","                    print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str}\")\n","                return\n","\n","        if (self.flag == 0) and (iter % print_every == 0):\n","            print(f\"Iteration: {iter} | loss_D: {loss_D_str} | loss_G: {loss_G_str} | test_mae: {loss_test_str}\")\n","\n","\n","    def train(self, iters, patience, print_every, N):\n","\n","        print(f\"GAN-PINN: {iters} iterations\")\n","        print(f\"a. PINN: {N} epochs --> Adam\")\n","        print(f\"b. Generator: 1 epoch --> Adam\\n\")\n","\n","        for iter in tqdm(range(1, iters + 1)):\n","            self.flag = 0\n","            self.early_stopping_applied = 0\n","\n","            real_data, noise = self.generate_data()\n","            fake_data = self.generator.model(noise)\n","\n","            loss_D = self.train_step(N, real_data, fake_data)\n","            loss_G = self.generator.train(fake_data, self.discriminator)\n","\n","            loss_test = self.discriminator.calculate_test_loss(self.test_data)\n","\n","            self.keep_checkpoints_and_print_losses(iter, patience, print_every,\n","                                                   loss_D, loss_G, loss_test)\n","\n","            if self.early_stopping_applied:\n","                print(f\"\\nEarly stopping applied at epoch {iter}.\")\n","                break"],"metadata":{"id":"hNUssAyw5MMh","executionInfo":{"status":"ok","timestamp":1710357800536,"user_tz":-120,"elapsed":535,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"9766h9FaaM_k"}},{"cell_type":"code","source":["# Data\n","x_min, x_max = -1, 1\n","t_min, t_max = 0, 1\n","Nx_domain = 200\n","Nt_domain = 100\n","Nx_init = 100\n","Nt_bound = 100\n","N_noise = 1_000\n","N_test = 100_000\n","\n","# Generator\n","Ng_layers = 3\n","Ng_neurons = 64\n","g_layers = [2] + Ng_layers * [Ng_neurons] + [2]\n","g_activation = nn.Tanh()\n","\n","# Discriminator\n","Nd_layers = 3\n","Nd_neurons = 20\n","d_layers = [2] + Nd_layers * [Nd_neurons] + [1]\n","d_activation = nn.Tanh()\n","\n","# Other\n","checkpoint_path = \"discriminator.pth\"\n","dtype = torch.float32\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# GAN-PINN initialization\n","gan_pinn = GAN_PINN(\n","    x_min, x_max,\n","    t_min, t_max,\n","    Nx_domain, Nt_domain,\n","    Nx_init, Nt_bound,\n","    N_test, N_noise,\n","    g_layers, g_activation,\n","    d_layers, d_activation,\n","    checkpoint_path\n",")\n","\n","# Training\n","iterations = 100\n","patience = 10\n","print_every = 1\n","num_epochs_adam = 100\n","\n","gan_pinn.train(iterations, patience, print_every, num_epochs_adam)"],"metadata":{"id":"Mxs5oZzT-PIf","colab":{"base_uri":"https://localhost:8080/","height":327,"referenced_widgets":["f099a7910e3d49c1b86f94c42e49a137","cae9659eff104d4d968ef37f00c1e681","7054cdb97e5b4c74925c28a03bd337d0","0c15bd3fee30414d9cf3b33fc3a417e4","266f3aeeac9b49daacc058868da37db0","f684665812554899ba21a9d048240d4f","a419a46a32c44916afcf6ba454222798","be3f29da0cfb465f8c260d30278c8a59","6696fdb156e443039f0311d6a36a0926","5989222a2ebc444f84585967b7f4bcde","e0516bc5d49244409df1905c4f3c3130"]},"executionInfo":{"status":"ok","timestamp":1710357829985,"user_tz":-120,"elapsed":26400,"user":{"displayName":"Achilleas Palaskos","userId":"04608072963754583562"}},"outputId":"53236b7d-db08-430f-a81d-12543410e95b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["GAN-PINN: 100 iterations\n","a. PINN: 100 epochs --> Adam\n","b. Generator: 1 epoch --> Adam\n","\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f099a7910e3d49c1b86f94c42e49a137"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Iteration: 1 | loss_D: 3.18e-01 | loss_G: -3.87e-03 | test_mae: 8.56e-02 - *Checkpoint*\n","Iteration: 2 | loss_D: 2.55e-01 | loss_G: -5.56e-03 | test_mae: 1.24e-01\n","Iteration: 3 | loss_D: 1.99e-01 | loss_G: -5.07e-03 | test_mae: 1.61e-01\n","Iteration: 4 | loss_D: 1.64e-01 | loss_G: -3.20e-03 | test_mae: 1.51e-01\n","Iteration: 5 | loss_D: 1.33e-01 | loss_G: -3.07e-03 | test_mae: 1.46e-01\n","Iteration: 6 | loss_D: 1.15e-01 | loss_G: -7.41e-04 | test_mae: 1.39e-01\n","Iteration: 7 | loss_D: 1.09e-01 | loss_G: -2.45e-03 | test_mae: 1.33e-01\n","Iteration: 8 | loss_D: 1.00e-01 | loss_G: -1.96e-03 | test_mae: 1.50e-01\n","Iteration: 9 | loss_D: 1.06e-01 | loss_G: -1.20e-03 | test_mae: 1.44e-01\n","Iteration: 10 | loss_D: 1.07e-01 | loss_G: -1.37e-03 | test_mae: 1.28e-01\n","\n","Early stopping applied at epoch 10.\n"]}]}]}